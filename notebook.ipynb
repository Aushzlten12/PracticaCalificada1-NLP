{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c71af0",
   "metadata": {},
   "source": [
    "# Proyecto 4: Pipeline de preprocesamiento\n",
    "\n",
    "Usando el dataset de 5,000 oraciones de `nlp_prueba_cc0c2_large.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ee3e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_825/3045226282.py\", line 1, in <module>\n",
      "    import torchtext\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torchtext/__init__.py\", line 3, in <module>\n",
      "    from torch.hub import _get_torch_home\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/usr/local/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37874948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos pandas para almacenar el dataset\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"data/nlp_prueba_cc0c2_large.csv\")\n",
    "df.head()\n",
    "\n",
    "assert \"Texto\" in df.columns, \"El CSV debe tener la columna 'Texto'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "691a9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
    "import torchtext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acade34",
   "metadata": {},
   "source": [
    "## Tres pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77a7498",
   "metadata": {},
   "source": [
    "### Crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8c568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3003, Test size: 2002\n",
      "Vocab size (train): 73\n",
      "Muestra de vocab: ['<unk>', '<pad>', 'en', 'de', 'es', 'para', 'Implementar', 'proyectos', 'reales', 'Los', 'pero', 'son', 'No', 'entiendo', 'cómo', 'funciona', 'la', 'La', 'NLP', 'curso']\n",
      "OOV rate (test vs train vocab): 0.0000\n",
      "\n",
      "=== Ejemplo TEST ===\n",
      "Texto:  The course de NLP es impresionante\n",
      "Tokens: ['The', 'course', 'de', 'NLP', 'es', 'impresionante']\n",
      "Idxs:   [0, 0, 3, 18, 4, 45] \n",
      "\n",
      "Texto:  Los proyectos are done\n",
      "Tokens: ['Los', 'proyectos', 'are', 'done']\n",
      "Idxs:   [9, 7, 0, 0] \n",
      "\n",
      "Texto:  Procesar text works impresionante\n",
      "Tokens: ['Procesar', 'text', 'works', 'impresionante']\n",
      "Idxs:   [0, 0, 0, 45] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# ============ \n",
    "# 1) Dataset base (ejemplo: df[\"Texto\"])\n",
    "# ============\n",
    "texts = df[\"Texto\"].astype(str).tolist()\n",
    "\n",
    "print(f\"Total size (usado para vocab): {len(texts)}\")\n",
    "\n",
    "# ============ \n",
    "# 2) Tokenizador crudo (regex)\n",
    "# ============\n",
    "tokenizer_regex = re.compile(\n",
    "    r\"[A-Za-zÁÉÍÓÚÜÑáéíóúüñ]+(?:[-'][A-Za-zÁÉÍÓÚÜÑáéíóúüñ]+)*|\\d+(?:[.,]\\d+)?\"\n",
    ")\n",
    "\n",
    "def tokenize_crudo(text: str):\n",
    "    return tokenizer_regex.findall(text)\n",
    "\n",
    "# ============ \n",
    "# 3) Vocabulario desde TODO el corpus\n",
    "# ============\n",
    "def yield_tokens(sentences):\n",
    "    for text in sentences:\n",
    "        yield tokenize_crudo(text)\n",
    "\n",
    "specials = [\"<unk>\", \"<pad>\"]\n",
    "vocab = build_vocab_from_iterator(yield_tokens(texts), specials=specials, min_freq=1)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])  # OOV -> <unk>\n",
    "\n",
    "PAD_IDX = vocab[\"<pad>\"]\n",
    "UNK_IDX = vocab[\"<unk>\"]\n",
    "\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "print(\"Muestra de vocab:\", vocab.get_itos()[:20])\n",
    "\n",
    "# ============ \n",
    "# 4) Dataset y DataLoader (opcional)\n",
    "# ============\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sentences, tokenizer, vocab):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokenizer(self.sentences[idx])\n",
    "        ids = self.vocab.lookup_indices(tokens)\n",
    "        return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch_tensors):\n",
    "    return pad_sequence(batch_tensors, batch_first=True, padding_value=PAD_IDX)\n",
    "\n",
    "dataset = CustomDataset(texts, tokenize_crudo, vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# ============ \n",
    "# 5) Función de OOV\n",
    "# ============\n",
    "def oov_rate(sentences, tokenizer, vocab, unk_idx):\n",
    "    total, oov = 0, 0\n",
    "    for s in sentences:\n",
    "        ids = vocab.lookup_indices(tokenizer(s))\n",
    "        total += len(ids)\n",
    "        oov += sum(1 for i in ids if i == unk_idx)\n",
    "    return (oov / total) if total > 0 else 0.0\n",
    "\n",
    "# ============ \n",
    "# 6) Ejemplos de code-switching\n",
    "# ============\n",
    "code_switching_examples = [\n",
    "    \"The course de NLP es impresionante\",\n",
    "    \"Los proyectos are done rápidamente\",\n",
    "    \"Procesar text works impresionante\"\n",
    "]\n",
    "\n",
    "print(\"\\n=== Code-switching ===\")\n",
    "for s in code_switching_examples:\n",
    "    toks = tokenize_crudo(s)\n",
    "    ids = vocab.lookup_indices(toks)\n",
    "    rate = oov_rate([s], tokenize_crudo, vocab, UNK_IDX)\n",
    "    print(\"Texto: \", s)\n",
    "    print(\"Tokens:\", toks)\n",
    "    print(\"Idxs:  \", ids)\n",
    "    print(\"OOV rate:\", f\"{rate:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ebeeb",
   "metadata": {},
   "source": [
    "### Normalizado(minúsculas, sin puntuación)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8598774e",
   "metadata": {},
   "source": [
    "### normalizado+lematizado (spaCy en español)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
